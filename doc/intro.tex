% -*-LaTeX-*-

\section{Introduction}

%
%  More storage devices
%    More failures
%    More places your data could be--harder to manage
%  One solution:  The cloud
%    Put all your data at Google or Amazon
%    Alleviates the failure and management problems
%  Limitations of the cloud model
%    Requires you to be on-line (even phones don't always have net access)
%    Potentially uses lots of network bandwidth to the outside world
%    Creates massive single points of failure
%    Creates need to support storage provider business model
%         (e.g., why pay Amazon S3 charges if you don't have to?)
%  But don't really need storage provider's hardware, just management
%    People usually have enough raw storage on devices for their data
%          Storage growing faster than net connectivity (cite Rodrigues)
%    People lose servers, desktop machines, and cell phones,
%          but usually not all at once
%  Suggests an alternative:  Personal clouds
%    Serverless cloud model based on your own devices
%    Example of taking data to work on cell phone
%  Requires a new data model
%    Don't want to copy files manually all the time--too inconvenient
%    Don't want a network file system
%          Synchronous network file system too dependent on network
%          Coda/Ficus still require server which requires maintenance
%    We advocate new type of FS:  Update locally, propagate asynchronously
%  Roadmap
%

Users have an increasing number of devices with sizable data storage.
PDAs, digital audio players, cell phones, and cameras will all soon
provide storage capacities comparable to today's laptops.  The ability
to carry around more storage opens up new opportunities, but also
creates complications.  First, more devices mean more failures.
People are more likely to lose or damage a cell phone or PDA than a
desktop machine; yet when cell phones have 60~GB of storage, they will
likely contain data the owner cannot afford to lose.  Second, more
devices mean there are more places any given file may live. Whatever
file a user wants is then less likely to be on the device he or she is
currently using.  Users will thus somehow need to manage their data by
transferring files between devices.

One solution to these problems is to store all data ``in the
cloud''---i.e., to keep the primary copy of data at an external
service provider such as Amazon or Google, rather than in a user's own
devices.  This trend is particularly evident with web mail, which many
find preferable to running their own mail servers.  Web mail solves
the problem of synchronizing saved mail accessed from multiple
clients.  It also saves end users from dealing with server failures.
Web sites such as Google Docs promise a similar experience for a
broader range of applications.

Unfortunately, the cloud model has a number of limitations.  In many
cases, users need Internet connectivity to access their data.  Yet
devices---even cell phones---do not always have network connectivity.
Moreover, the cloud model unnecessarily consumes precious wide-area
network bandwidth even when two devices on the same network share
files.  Worse yet, widespread dependence on a small number of storage
providers creates a dangerously large central point of failure.
Someone could easily take down Amazon~S3 just as a Pakistani ISP
recently caused a world-wide blackout of YouTube.  Finally, the cloud
model requires service providers to recover costs.  Some applications,
such as email, can achieve this through advertising.  Others (such as
those based on Amazon~S3) require fees to the storage provider.  In
these cases an alternative that does not require fees would be
preferable for users.

Fortunately, two trends suggest an alternative model that may be
preferable for many users.  First, the raw storage owned by users is
plentiful and growing faster than Internet connection speeds.  From
1990 to 2005, the time required to transmit a typical home user's hard
disk contents over the wide-area network increased from 0.6 to 120
days~\cite{rodrigues:multi-hop}.  Usable storage capacity of ``the
cloud'' is therefore limited by bandwidth to something much smaller
than local storage.  Second, as users get more devices, they have
access to more failure independence.  Though we often lose servers,
desktop machines, laptops, cell phones, or PDAs, any single person is
unlikely to lose all of their devices simultaneously.

These trends enable a data management model we term \emph{personal
  clouds}.  A personal cloud is a file system in which multiple
devices each store a local copy of every file.  Modifications
propagate between devices opportunistically as network conditions
permit.  For instance, modifications made on a user's home machine
might automatically propagate to her laptop over the local network; at
work the next day the laptop could automatically push the changes out
to a local server.  Though changes also propagate over the wide area
network, personal clouds exploit the higher bandwidth of physically
transported devices to synchronize far more data than would otherwise
be practical.  Moreover, should any device fail, its replacement can
re-initialize itself from any existing copy.

This paper presents \emph{pFS}, a network file system that implements
personal clouds.  Unlike traditional file systems, pFS makes all
updates locally and propagates them asynchronously to other devices
sharing the same file system, ensuring current network conditions do
not slow down applications.  Moreover, clients of a particular pFS
file system store every file.  There is no ``master'' or primary copy
of the data.  All clients are equal, and any client--client
communication patterns are permissible.  When concurrent updates occur
on different devices, pFS reconciles the changes, and exposes any
conflicts for applications to resolve.

pFS is far from the first network file system to support disconnected
operation.  Indeed, we rely heavily on ideas introduced by previous
file systems such as Ficus~\cite{page:ficus} and
CODA~\cite{kistler:coda}.  Our contributions are two-fold.  First, by
eliminating the distinction between clients and servers, pFS provides
a new usage model that provides a more viable alternative to the
``cloud'' model.  In particular, pFS eliminates the need for any
high-reliability components, and also for any system administrative
support.  pFS works fine even in situations where no replica has a
publicly routable IP address.

Second, pFS capitalizes on hardware trends to gain a large amount of
simplicity.  The fact that storage is becoming plentiful allows
devices to \emph{replicate} file systems rather than \emph{cache}
parts of them.  Thus, server replication and disconnected operation
are one and the same mechanism with pFS, and there is no need for
complex server-side logic for such tasks as backup and volume
migration.  Unlike some previous file systems, pFS handles
reconciliation in terms of directory entries, rather than files, which
at least in pFS's context seems reduce the number of reconciliation
corner cases.  pFS is also structured around a single internal
function, \texttt{pfs\_set\_entry}, in terms of which all the file
system modifications can be straight-forwardly implemented.  Thus,
while previous file systems required a large amount of engineering
effort, pFS is only 10,000 lines of C code and was implemented by a
single student in just over three months.  Nonetheless, pFS is a
useful system providing better performance than NFS (though of course
it also provides weaker consistency than NFS).

The next section discusses related work.  Section~\ref{sec:model}
further motivates the ``personal cloud'' paradigm.
Section~\ref{sec:vers} describes the data structures around which pFS
is organized and discusses conflict resolution.
Section~\ref{sec:impl} gives the details of the implementation.
Section~\ref{sec:eval} evaluates the pFS implementation, after which
we briefly discuss future work and conclude.

% Local Variables:
% tex-main-file: "main.ltx"
% tex-command: "make;:"
% tex-dvi-view-command: "make preview;:"
% End:
